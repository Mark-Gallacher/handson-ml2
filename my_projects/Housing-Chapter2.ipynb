{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb1d817-0b14-4048-8418-2ae33662be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "## some modules are imported later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c770c-19fd-4f49-baa2-b108466b550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import is_classifier\n",
    "\n",
    "logr = LogisticRegression()\n",
    "type(logr)\n",
    "is_classifier(logr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45080ab7-8ea8-4c26-89a2-d4b3b1dd1d8a",
   "metadata": {},
   "source": [
    "# Looking at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16e0e7-1450-4cdf-92fb-a2b32f65858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"../datasets/housing/housing.csv\")\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167734f-3807-4041-9793-8079a4bb3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's see how many columns and rows we have. This also highlights the number of null values which may need to be dealt with.\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab90525-1e18-45ad-98bd-c9c98dab5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All of the columns appear to be numeric, apart from the last one, ocean_proximiity, which is an object. Let's explore what that is.\n",
    "housing[\"ocean_proximity\"].value_counts()\n",
    "## Looks like it is catagorical, with levels, INLAND, NEAR OCEAN, NEAR BAY and ISLAND."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd52227-ffed-47fb-83af-a6e789734771",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's look at the numerical summary\n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a2463-0109-4970-84c6-e93284a82c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "## Let's visualise the distributions of the numeric variables\n",
    "housing.hist(bins = 50, figsize = (20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56a34e-5921-421c-948d-950c38d463f0",
   "metadata": {},
   "source": [
    "# Splitting the Data into Testing and Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c66d4c-4299-4ea6-b3a2-389bdd5ed923",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if out groups are equal, then we can simply split our data using the train_test_split() function.\n",
    "## providing a random state ensures consistency if ran many times - this function is extracting rows from a index randomly generated, \n",
    "## so the same rows are removed every time we run this\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4df738-2627-4ab0-902c-3a8416d304a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## However when we make income categorical, this method of splitting the data will introduce sampling bias, as not all groups are equal.\n",
    "## One useful solution is to use stratified sampling, to ensure the train and test data have the same proportions of the groups.\n",
    "\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],                ## what column do you want to split into bins?\n",
    "                              bins = [0., 1.5, 3.0, 4.5, 6., np.inf],  ## what do the bins look like?\n",
    "                              labels = [1, 2, 3, 4, 5])                ## what are the names of these bins?\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = .2, random_state = 42)\n",
    "## the for loop is not really iterating, just extracting the values and mapping them\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb05c5e-6f91-4bd0-9728-bb5e8ffadcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1, i2 in split.split(housing, housing[\"income_cat\"]):\n",
    "    print(i1, i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a441e2c-ccdf-443e-b152-6e48d0a96d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's double check the proportions, to make sure it worked\n",
    "strat_train_set[\"income_cat\"].value_counts() / len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d2e47c-a79f-4314-bf9e-04c22492d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's double check the proportions, to make sure it worked\n",
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa10c56-997b-473a-8e38-3e52010c0e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we don't need to convert the income variable into a factor, but this is useful to be aware of\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42aed1e-472d-43f6-b448-78e71fcaf2a4",
   "metadata": {},
   "source": [
    "# Visualising the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3221c46f-7e66-472e-955d-0dd3488f5b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()\n",
    "## Let's see what areas are more density populated in our sample by using a scatterplot with transparency.\n",
    "housing.plot(kind = \"scatter\", x = \"longitude\", y = \"latitude\", alpha = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d108b0-250b-44de-b7e6-981e3b8cdfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try to recrete this graphic but adding in details about the house values, to see if there are any obvious patterns.\n",
    "housing.plot(kind = \"scatter\",                   ## Type of graph\n",
    "             x = \"longitude\",                    ## What goes on the x axis\n",
    "             y = \"latitude\",                     ## What goes on the y axis\n",
    "             alpha = .4,                         ## The transparency to use\n",
    "             s = housing[\"population\"]/100,      ## How to side the points - i.e by population\n",
    "             label = \"population\",               ## The name of the legend\n",
    "             figsize = (10, 7),                  ## The size of the graph\n",
    "             c = \"median_house_value\",           ## How to colour the points - i.e by prize\n",
    "             cmap = plt.get_cmap(\"jet\"),         ## What palette to use, plt.get_cmap()\n",
    "             colorbar = True                     ## Should we show the colourbar?\n",
    "            )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa065e-089f-49b6-9017-257135602291",
   "metadata": {},
   "source": [
    "So we can now see that the areas near the ocean are typically higher in value. Also smaller areas tend to be cheaper too, likely less influenced by the demand that comes from higher population density.\n",
    "\n",
    "Next, let's check for correlation between all of our variables, since this dataset is relatively small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb5f12-8375-44af-a940-9c8474c58218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix = housing.corr(method = \"spearman\", numeric_only = True)\n",
    "# corr_matrix[\"median_house_value\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49272288-f797-474e-8093-7165fb07a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr(method = \"pearson\", numeric_only = True)\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc597a5-9367-41cc-9d93-594a8d63eeb7",
   "metadata": {},
   "source": [
    "Looks like we have mostly weak correlations for `median_house_value`, but `median_income` is moderately correlated with a value of 0.687. Surprising, total_rooms only has a correlation of 0.13. Maybe having room size, number of bedrooms, number of bathrooms or total area would be better.\n",
    "\n",
    "Another way to see correlation is to use the `pandas.plotting module`, to get the function `scatter_matrix()`. We set the diagonal to *\"kde\"*, which means the kernel density estimate. Again, the data does not appear to be normally distributed, and the limits on the data are becoming more clear. Especially for our target variable, the limit of 500,000 generates an almost solid line. There are also lines around 350,000 and 450,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35437b4-0f0c-4a68-a127-0b31dae21fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\"]\n",
    "\n",
    "pd.plotting.scatter_matrix(\n",
    "    housing[attributes],\n",
    "    figsize = (12, 9), \n",
    "    diagonal = \"kde\", \n",
    "    alpha = .3\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b457f1-5d58-4583-8e33-b7fff4f11b0c",
   "metadata": {},
   "source": [
    "Some of our variables could be improved, for example *households* and *total_bedrooms* could be combined to get number of bedroom in a household. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa991bf7-e05d-4002-a6e5-f3231379519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_bedrooms\"] / housing[\"households\"]\n",
    "housing[\"bedroom_per_room\"] = housing[\"total_bedrooms\"] / housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"] = housing[\"population\"] / housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064f2f4-b5ba-4acb-9b52-5a61f2522adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr(method = \"pearson\", numeric_only = True)\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a87dc5-9f59-4b3a-9e4c-55ec3b9eab91",
   "metadata": {},
   "source": [
    "# Preparing for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d366e-d0ee-4d07-9bfa-7e74fea1eeeb",
   "metadata": {},
   "source": [
    "We are going to revert back to the original traning data, but we can come back to do some feature engineering and generate better variables.\n",
    "\n",
    "## Categorical Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f80cb7-1c44-4a3e-9ce5-4d78414413c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## .drop() creats a copy first so we still have the median_house_value column, and that's why the second line works too.\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis = 1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "housing.info() ## 16,512 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae0c70-c893-4bab-a0f9-e22ef52cc2a2",
   "metadata": {},
   "source": [
    "The first thing we need to deal with is the missing values, we have a few options:\n",
    "- delete the column(s) containing missing values\n",
    "- delete the row(s) containing missing values\n",
    "- fill the missing values for another value (Such as the mean, median, zero, etc...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfabf64-d0a5-4d6a-a422-fa6d6c332f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removes the entire column\n",
    "# housing.drop(\"total_bedrooms\", axos = 1)\n",
    "### Removed the rows\n",
    "# housing.dropna(subset=[\"total_bedrooms\"])\n",
    "### Fills in the missing values\n",
    "median = housing[\"total_bedrooms\"].median()\n",
    "# housing[\"total_bedrooms\"].fillna(median, inplace = True)  ## Depreciated syntax, replace more explicitly.\n",
    "housing[\"total_housing\"] = housing[\"total_bedrooms\"].fillna(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef8b537-7e96-4094-9e92-b7154612ef95",
   "metadata": {},
   "source": [
    "One not so obvious thing to remember for the last option, is that this median value needs to be applied globally. So it needs to be available to the testing data as well as new data, if we are training incrementally.\n",
    "This could become problematic to keep tract of, but `Scikit-learn` has a useful class called `SimpleImputer`. This is for univariate values, as the multivariate alternative is the `IterativeImputer`. There is also the K-nearest neighbours imputer, likely for categorical missing values:`KNNImputer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a5977-f609-402f-b379-d1b2fe77ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy = \"median\") ## other strategies include: mean, constant and most-frequent (mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0ef563-0faf-4307-b4a5-3d367e6b4e18",
   "metadata": {},
   "source": [
    "To use this imputer, we need to fit it to our data but it only works for numerical values. First we need to remove the non-numerical values, i.e. the `ocean_proximity` category. Then we can use the `SimpleImputer`'s method `fit()` to calculate the median of all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd9cdf-27eb-42fc-997b-483ac0604246",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num = housing.drop(\"ocean_proximity\", axis = 1)\n",
    "\n",
    "## calculate the median for each of the columns\n",
    "imputer.fit(housing_num)\n",
    "\n",
    "## to see the imputer values, we can use the attribute statistics_\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b4241-3b78-4593-9715-28a76bed1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now transform the original dataframe\n",
    "X = imputer.transform(housing_num)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76893a22-7533-4841-9f06-3d1c62b67061",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To convert this numpy array back into a pandas dataframe, we can:\n",
    "housing_tr  = pd.DataFrame(X, columns = housing_num.columns, index = housing_num.index)\n",
    "\n",
    "## alternatively, we could use the convenient, fit_transform() method, although I don't know if this outputs a Panda's Dataframe\n",
    "housing_tr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fececa2b-130c-44ae-885c-cd7f7fd1f45e",
   "metadata": {},
   "source": [
    "Next we need to handle the categorical variable. Machine learning algorithms are numerical, we could convert the categories into a dummy variable, like what R does for linear models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3611b-ebc0-4574-9800-ab6d9e1543b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]] ## double [[ ]] means it returns a pandas dataframe instead of a series.\n",
    "housing_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0438d26-4bf6-4dad-a922-5e872be731ce",
   "metadata": {},
   "source": [
    "We could also use an ordinal encoder, it does make the assumption that the ordinal values are equally spaced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c05ead9-4c6d-4ee3-b72b-4e09496c7bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd654d-6b30-47d3-b74b-bddba00b394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d222782-51ff-44e2-a63e-e3d25580268e",
   "metadata": {},
   "source": [
    "Maybe a better solution is **one-hot encoding**, where we create a vector containing zero's in all places apart from one, the category it represents.\n",
    "\n",
    "If we had three groups, it would look like:\n",
    "- Group 1 = [1, 0, 0]\n",
    "- Group 2 = [0, 1, 0]\n",
    "- Group 3 = [0, 0, 1]\n",
    "\n",
    "In general, the length of the vector is the number of groups, and we create a *sparse* vector to represent the categories. The Sparse vector comes from SciPy, that is where the only values stored represents the index of the non-zero values. So if we have a vector of length 20, and the 13th element is a 1, then the sparse matrix/vector would store 13. This prevents the waste of memory to store lots of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f028f8f0-d9a3-4845-b4d5-d095feab4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb3735e-73d3-4253-a503-c74038b928f9",
   "metadata": {},
   "source": [
    "We can convert this to a *dense* matrix is we want, by using the `toarray()` method, which returns a NumPy array/matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11dea4e-0406-4fb1-8802-9fe390442192",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a752a-2aa1-47ae-b5be-610576498001",
   "metadata": {},
   "source": [
    "This method is not perfect though, if we have a lot of categories, this could negatively impact training speeds. One potential and common solution is to use *representation learning*, where a numerical value associated with only one category is given, this could be the population or the GDP of the country. This is called embedding, as we are embedding a low-dimensional feature to represent a categorical feature into the data, so that the machine can quickly learn to differentiate between the levels of the category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6f10e-0e8b-4d6d-81d1-1c9782eea6aa",
   "metadata": {},
   "source": [
    "## Defining our own Transformers\n",
    "\n",
    "Defiining our own transformers can help automate the feature enginerring so that we can test more parameters and save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7493bc-cea3-4e85-afaa-b7e6ac52182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "## column index for the matrix/dataframe\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "class CominedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    ## we use BaseEstimate to avoid using *args and **kwargs since it has get_params() and set_params() methods\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        return self ## that's it\n",
    "\n",
    "    ## we are only transforming the features, so we don't need y.\n",
    "    def transform(self, X):\n",
    "        ## define the new panda's series containing the engineered features.\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "\n",
    "        ## check if we also want bedrooms per room\n",
    "        if self.add_bedrooms_per_room:\n",
    "            \n",
    "            bedrooms_per_room =  X[:, bedrooms_ix] / X[:, household_ix]\n",
    "            ## add to original dataframe\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "            \n",
    "        else:\n",
    "            ## add to original dataframe\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298852c0-1bbe-4978-85a7-058df5c2cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_adder = CominedAttributesAdder(add_bedrooms_per_room = False)\n",
    "housing_extra_attribs= attr_adder.transform(housing.values)  ## values attribute returns a numpy array.\n",
    "housing_extra_attribs ## returns the updated numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5061e2ab-60f9-460e-9280-5c1a9fd89872",
   "metadata": {},
   "source": [
    "## Feature Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee6fe8-eadb-4915-9cf3-6307ccb6b464",
   "metadata": {},
   "source": [
    "The two main types of scaling are *normalisation* and *standardisation*. Normalisation (also called Min-Max scaling) bounds the feature to 0 and 1 by subtracting each value by the minimum value, then dividing by the different of the maximum and minimun value. That mean if the minimun value was 5, and the maximum was 10, the value 5 becomes 0 / 5 and 10 becomes 5 / 5. \n",
    "\n",
    "Standardisation is when we find the difference between the value and the mean, x - mu, then divide by the standard deviation, delta. This results in a distribution with a mean of zero, and a variance and SD of 1. This is less sensitive to outliers, compared to Min-Max scaling but does not offer the strict boundaries that would be helpful. For example, neural networks often expect values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab0a7e-4d98-4b0f-8c38-fd181a591a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler ## the names of the scalers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f3193-4e6e-429d-b25d-1fd9aae1e981",
   "metadata": {},
   "source": [
    "## Transformation Pipelines\n",
    "\n",
    "Sometimes we want a chain of transformations to occur in a certain order, and stored in a value that can be used multiple times.\n",
    "This is called a pipeline and sci-kit learn has built in tools to do exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97951706-78dd-419c-8e40-648251ba2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy = \"median\")),\n",
    "    (\"attribs_adder\", CominedAttributesAdder()),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0df3dc-5823-47ad-b866-e10660e45e0a",
   "metadata": {},
   "source": [
    "So far we have been processing the numerical and categorical columns separately, but this may not be the most concise way to do it. Scikit-Learn has a module called `ColummnTransformer`, where we can specify how we want each column to be transformed. This allows us to use our `num_pipeline` on the numerical columns and modify the categorical columns at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371fad4c-1a0c-4374-bae3-7c305dc6b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ## name of step, the function to apply, the columns to apply on\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    ## name, function, target(s)\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs)\n",
    "])\n",
    "\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a534338a-1fe0-48ad-b952-1d831c0a6998",
   "metadata": {},
   "source": [
    "# Training and Selecting a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6b14b-4f56-4b08-8a53-b5451ba5bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def train_model(model, model_name):\n",
    "    \n",
    "    model.fit(housing_prepared, housing_labels)\n",
    "    predictions = model.predict(housing_prepared)\n",
    "\n",
    "    joblib.dump(model, \"models/\" + model_name + \".pkl\")\n",
    "    \n",
    "    rmse = root_mean_squared_error(housing_labels, predictions)\n",
    "    # tree_rmse = np.sqrt(tree_mse)\n",
    "    return f\"The Root Mean Square Error is ${rmse:,.2f} ({rmse * 100 / np.median(housing_labels):.2f}%) when the median price is ${np.median(housing_labels):,.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff56aac5-8748-4187-bc65-b399deb8f968",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08dcdc-7d49-4fd3-a32d-65e92594e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "train_model(lin_reg, \"linear_regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f45ca33-e4dc-456d-8871-aa4166d9c81e",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aab9ab-1929-4574-8210-56e7292e41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "train_model(tree_reg, \"decision_tree_regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a7b20-93b6-466b-8764-fb5c80f3a41f",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63742904-e7f3-4292-8f97-039ef48263e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel = \"linear\", gamma = \"auto\", C = 1, max_iter = 5000)\n",
    "train_model(svm_reg, \"support_vector_machine_regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17ec22-123a-46ed-8856-dc91dba01443",
   "metadata": {},
   "source": [
    "## Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb66fa08-40ae-4f89-b067-cc34fcfc726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "br_reg = BayesianRidge(max_iter = 5000)\n",
    "\n",
    "train_model(br_reg, \"Bayesian_ridge_regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46f9fe-b60d-4c71-9119-d636b75f4fd3",
   "metadata": {},
   "source": [
    "## Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582d99f8-7e54-4db3-91b7-8453b6eb89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "gp_reg = GaussianProcessRegressor(n_restarts_optimizer = 0, normalize_y = False, random_state = 0)\n",
    "\n",
    "train_model(gp_reg, \"Gaussian_Process_regression\")\n",
    "## this performs much better when the labels are also scaled - worth looking into"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0dc44-e6bc-4007-b9b2-7ab455718dab",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a94d63-2395-4a65-9c6f-8b9c42c4b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "train_model(rf_reg, \"Random_Forest_regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87259de-db32-46c2-84b7-e71c54e131fb",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07873fe8-a37b-4b0a-9ca2-be5afa2c024e",
   "metadata": {},
   "source": [
    "Now we are at an interesting point, the linear regression was too simple and is underfitting our data but the decision tree was overfitting our data (naturally). We have a few options, we could make our linear model more complex, maybe transform some of the features, introduce complexity with polynomials or collect more data. We could also try to constrain our tree, limit the number of branches it can have and look at the main branches to see how it is decising between the groups. \n",
    "\n",
    "First, let's explore the decision tree in more detail. We could split our training set again, using the `train_test_split()` or use cross-validation to get an idea how well it can generalise to new data. Cross-validation can inform us how well our model is going (mean) and how stable or reliable that estimation is (standard deviation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6001e071-05f1-416c-a854-10a1de6e3703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(score):\n",
    "    rmse = np.sqrt(-score)\n",
    "    print(rmse)\n",
    "    print(f\"Mean: ${rmse.mean():,.2f}\")\n",
    "    print(f\"SD: ${rmse.std():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbebd95-c0bf-46f1-bd04-b230173bae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category = ConvergenceWarning)\n",
    "\n",
    "## CV expects a utility function instead of a cost function, so larger values are better so make the mean_squared_error negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77151d15-953c-4833-ad11-d86c5a544eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_scores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "display_scores(tree_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27318f49-eb24-4661-9829-adf490cb2c5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rf_scores = cross_val_score(rf_reg, housing_prepared, housing_labels, scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "# display_scores(rf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f392a26c-f830-4571-a644-b1ecd79f4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "display_scores(lin_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3661dc7-1db6-4cea-af4f-990ac64f9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"mean_squared\" : \"neg_mean_squared_error\", \n",
    "    \"mean_abs\" : \"neg_mean_absolute_error\", \n",
    "    \"root_mean_squared\" : \"neg_root_mean_squared_error\"\n",
    "}\n",
    "\n",
    "cv_test = cross_validate(\n",
    "    estimator = lin_reg, \n",
    "    X = housing_prepared, \n",
    "    y = housing_labels,\n",
    "    scoring = metrics, \n",
    "    cv = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d7460-c10a-47f9-9e14-3ddeefbef6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488dfa55-332d-4fcd-8782-4e7aec8ce164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_scores = cross_val_score(svm_reg, housing_prepared, housing_labels, scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "# display_scores(svm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5daab-ed13-4560-bf56-1beee6ca8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# br_scores = cross_val_score(br_reg, housing_prepared, housing_labels, scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "# display_scores(br_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa0a31a-baac-49de-b12f-e5ad6c488395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import parallel_backend\n",
    "# with parallel_backend(\"threading\", n_jobs = 2):\n",
    "    # gp_scores = cross_val_score(gp_reg, housing_prepared, housing_labels, scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "# display_scores(gp_scores)\n",
    "## too compuationally expensive and not great - don't run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351a6b5-012d-4baa-93d3-d2cbe1c6a2b8",
   "metadata": {},
   "source": [
    "## Fine Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2eac62-3de7-4a8e-bc1b-ed75de65cfc2",
   "metadata": {},
   "source": [
    "Let's take the random forest model, since it is one of the best models and is not too computationally expensive.\n",
    "It has a few hyperparameters we might want to checkout:\n",
    "- `n_estimators` = number of trees in the forest - default is 100\n",
    "- `max_depth` = the maximum depth of the tree - default is None\n",
    "- `min_samples_split`= Minumum number of samples in a node, if less then it doesn't split\n",
    "- `max_features` = the number of features to look at when splitting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545cc6c5-3c36-45e7-9e77-472f8214c26b",
   "metadata": {},
   "source": [
    "### Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23f96b-b9ab-43d1-a585-f8bba80c5edb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## param~_grid should be a dictionary or a list of dictionaries\n",
    "param_grid = [\n",
    "    {\"n_estimators\" : [10, 30, 60], \"max_features\" : [6, 8], \"max_depth\" : [5, 10]},\n",
    "    {\"bootstrap\" : [True, False], \"n_estimators\" : [30], \"max_features\" : [8]}\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_cv = GridSearchCV(forest_reg, param_grid, cv = 5, scoring = \"neg_mean_squared_error\", return_train_score = True)\n",
    "\n",
    "grid_cv.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2769945-7867-4e55-908a-fed4f08f81b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;min_samples_split&#x27;: [2, 4, 8, 10, 12]}, refit=False,\n",
       "             scoring={&#x27;mean_abs&#x27;: &#x27;neg_mean_absolute_error&#x27;,\n",
       "                      &#x27;mean_squared&#x27;: &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;root_mean_squared&#x27;: &#x27;neg_root_mean_squared_error&#x27;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=2, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;min_samples_split&#x27;: [2, 4, 8, 10, 12]}, refit=False,\n",
       "             scoring={&#x27;mean_abs&#x27;: &#x27;neg_mean_absolute_error&#x27;,\n",
       "                      &#x27;mean_squared&#x27;: &#x27;neg_mean_squared_error&#x27;,\n",
       "                      &#x27;root_mean_squared&#x27;: &#x27;neg_root_mean_squared_error&#x27;})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeRegressor()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DecisionTreeRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">?<span>Documentation for DecisionTreeRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeRegressor()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'min_samples_split': [2, 4, 8, 10, 12]}, refit=False,\n",
       "             scoring={'mean_abs': 'neg_mean_absolute_error',\n",
       "                      'mean_squared': 'neg_mean_squared_error',\n",
       "                      'root_mean_squared': 'neg_root_mean_squared_error'})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_test = {\"min_samples_split\" : [2, 4, 8, 10, 12]}\n",
    "\n",
    "grid_cv_test = GridSearchCV(tree_reg, params_test, scoring = metrics, cv = 2, refit = False)\n",
    "grid_cv_test.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1a9bf0eb-7c2e-4fc0-914c-3843f72d208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.12226272, 0.10044372, 0.08889389, 0.09763849, 0.08416033]),\n",
       " 'std_fit_time': array([0.01756859, 0.00360096, 0.00557327, 0.01257479, 0.00252581]),\n",
       " 'mean_score_time': array([0.00350785, 0.00099969, 0.        , 0.        , 0.00175691]),\n",
       " 'std_score_time': array([0.00150347, 0.00099969, 0.        , 0.        , 0.00024867]),\n",
       " 'param_min_samples_split': masked_array(data=[2, 4, 8, 10, 12],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'min_samples_split': 2},\n",
       "  {'min_samples_split': 4},\n",
       "  {'min_samples_split': 8},\n",
       "  {'min_samples_split': 10},\n",
       "  {'min_samples_split': 12}],\n",
       " 'split0_test_mean_squared': array([-5.74593901e+09, -5.49940886e+09, -5.16729487e+09, -4.94114451e+09,\n",
       "        -4.80114194e+09]),\n",
       " 'split1_test_mean_squared': array([-5.37067988e+09, -5.29016683e+09, -4.98795575e+09, -4.80675514e+09,\n",
       "        -4.73857318e+09]),\n",
       " 'mean_test_mean_squared': array([-5.55830944e+09, -5.39478784e+09, -5.07762531e+09, -4.87394983e+09,\n",
       "        -4.76985756e+09]),\n",
       " 'std_test_mean_squared': array([1.87629565e+08, 1.04621017e+08, 8.96695632e+07, 6.71946847e+07,\n",
       "        3.12843799e+07]),\n",
       " 'rank_test_mean_squared': array([5, 4, 3, 2, 1]),\n",
       " 'split0_test_mean_abs': array([-49244.84944283, -48467.26867329, -46874.61833818, -46161.7192183 ,\n",
       "        -45430.71053981]),\n",
       " 'split1_test_mean_abs': array([-47610.34689922, -47480.64395591, -46007.89687442, -45154.61329504,\n",
       "        -44744.7653372 ]),\n",
       " 'mean_test_mean_abs': array([-48427.59817103, -47973.9563146 , -46441.2576063 , -45658.16625667,\n",
       "        -45087.7379385 ]),\n",
       " 'std_test_mean_abs': array([817.2512718 , 493.31235869, 433.36073188, 503.55296163,\n",
       "        342.97260131]),\n",
       " 'rank_test_mean_abs': array([5, 4, 3, 2, 1]),\n",
       " 'split0_test_root_mean_squared': array([-75801.97232321, -74157.99929093, -71883.89855738, -70293.27501885,\n",
       "        -69290.2730854 ]),\n",
       " 'split1_test_root_mean_squared': array([-73284.92257869, -72733.53302061, -70625.4610277 , -69330.766211  ,\n",
       "        -68837.29501044]),\n",
       " 'mean_test_root_mean_squared': array([-74543.44745095, -73445.76615577, -71254.67979254, -69812.02061493,\n",
       "        -69063.78404792]),\n",
       " 'std_test_root_mean_squared': array([1258.52487226,  712.23313516,  629.21876484,  481.25440392,\n",
       "         226.48903748]),\n",
       " 'rank_test_root_mean_squared': array([5, 4, 3, 2, 1])}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid_cv_test.cv_results_\n",
    "grid_cv_test.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815cf11-db85-4e0d-a41d-7153ce9fface",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d001e3e-7ea5-429a-883c-250fdedda89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4fb12-50fd-4f3e-8f59-9363e79757e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(-grid_cv.best_score_) ## $49,586.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f48354-142e-48ae-a565-28cd11c6b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_cv.cv_results_ get all the results out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161bf258-0aa9-43c0-8c2b-cdb3c5f8b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = grid_cv.cv_results_\n",
    "for mean_score, params in zip(cv_res[\"mean_test_score\"], cv_res[\"params\"]):\n",
    "    print(f\"${np.sqrt(-mean_score):,.2f} - params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d7690-d921-4cd9-99e9-1519be2abfa9",
   "metadata": {},
   "source": [
    "### Randomised Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d508b-b72e-47df-bc1e-3425d5286199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\" : randint(10, 100), \n",
    "     \"max_features\" : randint(3, 17), \n",
    "     \"max_depth\" : randint(3, 20),\n",
    "    \"bootstrap\" : [True, False]\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "randgrid_cv = RandomizedSearchCV(forest_reg, \n",
    "                                 param_grid, \n",
    "                                 cv = 5, \n",
    "                                 scoring = \"neg_mean_squared_error\", \n",
    "                                 return_train_score = True,\n",
    "                                 n_iter = 25, \n",
    "                                 n_jobs = 5)\n",
    "\n",
    "randgrid_cv.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264ec74-39b1-475e-b0d7-daa0030d83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "randgrid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745c87a-89cf-452d-b9b2-c805eaf8aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "randgrid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4249fc58-251e-40ed-80b8-ea2139187d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(-randgrid_cv.best_score_) ## $49,890.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee56e9-3cd6-412b-bc67-db66f558371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "randcv_res = randgrid_cv.cv_results_\n",
    "for mean_score, sd_score, params in zip(randcv_res[\"mean_test_score\"], randcv_res[\"std_test_score\"], randcv_res[\"params\"]):\n",
    "    print(f\"${np.sqrt(-mean_score):,.2f} (${np.sqrt(sd_score):,.2f}) - params: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d79f43-cf49-4ae0-9382-33f3e844c7b4",
   "metadata": {},
   "source": [
    "### Exploring the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c07a8-4443-46c6-97bd-d53f03277c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_attrs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_hhold\"]\n",
    "cat_encoder = full_pipeline.named_transformers_.cat.categories_[0]\n",
    "cat_attr = list(cat_encoder)\n",
    "attrs = num_attribs + extra_attrs + cat_attr\n",
    "\n",
    "## if we still had a dataframe instead of a list of numpy arrays, we could just use this to get the feature names\n",
    "# list(housing_prepared)\n",
    "\n",
    "sorted(zip(randgrid_cv.best_estimator_.feature_importances_, attrs), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96582156-93ad-4698-b28d-38fe01ebd06f",
   "metadata": {},
   "source": [
    "## Testing with Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b218fcf-7304-47df-8e60-e5bf704903e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing2 = pd.read_csv(\"../datasets/housing/housing.csv\")\n",
    "\n",
    "## get a list of the columns\n",
    "cols = [\"total_rooms\", \"total_bedrooms\", \"population\", \"households\", \"median_income\"]\n",
    "\n",
    "for col in cols:\n",
    "    housing2[col] = np.log1p(housing2[col])\n",
    "\n",
    "housing2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f4b551-7f25-43d9-b751-a3934f1df313",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "## Let's visualise the distributions of the numeric variables\n",
    "housing2.hist(bins = 50, figsize = (20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94104b01-3451-4458-8365-7cfe462edf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing2.drop(\"median_house_value\", axis = 1)\n",
    "y = housing2[\"median_house_value\"].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a398c-5902-4c2e-a248-a6455691216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"ocean_proximity\"].value_counts()\n",
    "\n",
    "num_attribs = list(X_train)\n",
    "cat_attribs = [num_attribs.pop(8)]  ## this remove ocean_proximity from the num_atribs\n",
    "\n",
    "## reminder of the full pipeline\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ## name of step, the function to apply, the columns to apply on\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    ## name, function, target(s)\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs)\n",
    "])\n",
    "\n",
    "housing_prepared2 = full_pipeline.fit_transform(X_train)\n",
    "\n",
    "## get the names for all the columns, including the new and formatted ones.\n",
    "all_columns = num_attribs + [\n",
    "    \"rooms_per_household\", \"population_per_household\", \"bedrooms_per_room\"] + [\n",
    "    \"<1H OCEAN\", \"INLAND\", \"ISLAND\", \"NEAR BAY\", \"NEAR OCEAN\"]\n",
    "\n",
    "housing_prepared2 = pd.DataFrame(housing_prepared2, columns = all_columns)\n",
    "housing_prepared2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a51262-89b6-4ee6-beb9-f3fa085221cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393395ba-f75b-45cd-9f15-e1d9f9de1463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ba37c-037c-42b9-bb3d-e00e401a6e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands-on-ml2",
   "language": "python",
   "name": "hands-on-ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
